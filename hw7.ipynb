{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning From Data - Homework 7\n",
    "## Ognen Nastov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt\n",
    "import time\n",
    "\n",
    "# problems 1-5 - validation\n",
    "\n",
    "# read input and test sets\n",
    "# d = 2\n",
    "# return X,Y where X = [[x1, ...]] and Y = [y1, ...]\n",
    "def read_training_set():\n",
    "    S = np.loadtxt(\"http://work.caltech.edu/data/in.dta\")\n",
    "    return S[:,0:2], S[:,2]\n",
    "\n",
    "def read_test_set():\n",
    "    S = np.loadtxt(\"http://work.caltech.edu/data/out.dta\")\n",
    "    return S[:,0:2], S[:,2]\n",
    "\n",
    "# X and Y have each N points\n",
    "# split into N-K points (training set) and K points (validation set)\n",
    "def split_set(X, Y, K):\n",
    "    N = np.size(X,0)\n",
    "    return X[0:N-K,:], Y[0:N-K], X[N-K:,:], Y[N-K:]\n",
    "\n",
    "# transformed input set is d = 7\n",
    "def transform_input_set(X):\n",
    "    N = np.size(X, 0)\n",
    "    X0 = np.ones([N,])\n",
    "    X1 = X[:,0]\n",
    "    X2 = X[:,1]\n",
    "    X3 = X1**2\n",
    "    X4 = X2**2\n",
    "    X5 = X1*X2\n",
    "    X6 = np.abs(X1-X2)\n",
    "    X7 = np.abs(X1+X2)\n",
    "    X_transformed = np.array([X0, X1, X2, X3, X4, X5, X6, X7]).T\n",
    "    return (X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve for model phi_0 through phi_k\n",
    "def solve_regression_k(X, Y, k):\n",
    "    w = np.dot(np.linalg.pinv(X[:,0:k+1]), Y)\n",
    "    return (w)\n",
    "\n",
    "# classification error for model phi_0 through phi_k\n",
    "def classification_error_k(w, X, Y, k):\n",
    "    Y_c = np.sign(np.dot(X[:,0:k+1],w))\n",
    "    error = np.count_nonzero(Y_c != Y) / len(Y)\n",
    "    return (error)\n",
    "\n",
    "# problem 1 - training & validation\n",
    "# K is size of validation set\n",
    "def problem_1(K):\n",
    "    X,Y = read_training_set()\n",
    "    Xt,Yt,Xv,Yv = split_set(X,Y,K)\n",
    "    Xtx = transform_input_set(Xt)\n",
    "    Xvx = transform_input_set(Xv)\n",
    "    w = {}\n",
    "    Eval = {}\n",
    "    for k in range(3,8):\n",
    "        w[k] = solve_regression_k(Xtx, Yt, k)\n",
    "        Eval[k] = classification_error_k(w[k], Xvx, Yv, k)\n",
    "    for k in range(3,8):\n",
    "        print(f\"k = {k} , Eval = {Eval[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 , Eval = 0.3\n",
      "k = 4 , Eval = 0.5\n",
      "k = 5 , Eval = 0.2\n",
      "k = 6 , Eval = 0.0\n",
      "k = 7 , Eval = 0.1\n"
     ]
    }
   ],
   "source": [
    "problem_1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smallest `Eval` is for `k=6`, answer is [d].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem 2 - training & testing\n",
    "# K is size of validation set\n",
    "def problem_2(K): \n",
    "    X,Y = read_training_set()\n",
    "    Xtst,Ytst = read_test_set()\n",
    "    Xt,Yt,Xv,Yv = split_set(X,Y,K)\n",
    "    Xtx = transform_input_set(Xt)\n",
    "    Xtstx = transform_input_set(Xtst)\n",
    "    w = {}\n",
    "    Eout = {}\n",
    "    for k in range(3,8):\n",
    "        w[k] = solve_regression_k(Xtx, Yt, k)\n",
    "        Eout[k] = classification_error_k(w[k], Xtstx, Ytst, k)\n",
    "    for k in range(3,8):\n",
    "         print(f\"k = {k} , Eout = {Eout[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 , Eout = 0.42\n",
      "k = 4 , Eout = 0.416\n",
      "k = 5 , Eout = 0.188\n",
      "k = 6 , Eout = 0.084\n",
      "k = 7 , Eout = 0.072\n"
     ]
    }
   ],
   "source": [
    "problem_2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smallest `Eout` is for `k=7`, answer is [e].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p3a.png)\n",
    "![](hw7_images/hw7p3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem 3 - training & validation with reversed sets\n",
    " # K is size of training set\n",
    "def problem_3(K):\n",
    "    X,Y = read_training_set()\n",
    "    Xv,Yv,Xt,Yt = split_set(X,Y,K) # reversed sets\n",
    "    Xtx = transform_input_set(Xt)\n",
    "    Xvx = transform_input_set(Xv)\n",
    "    w = {}\n",
    "    Eval = {}\n",
    "    for k in range(3,8):\n",
    "        w[k] = solve_regression_k(Xtx, Yt, k)\n",
    "        Eval[k] = classification_error_k(w[k], Xvx, Yv, k)\n",
    "    for k in range(3,8):\n",
    "        print(f\"k = {k} , Eval = {Eval[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 , Eval = 0.28\n",
      "k = 4 , Eval = 0.36\n",
      "k = 5 , Eval = 0.2\n",
      "k = 6 , Eval = 0.08\n",
      "k = 7 , Eval = 0.12\n"
     ]
    }
   ],
   "source": [
    "problem_3(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smallest `Eval` for `k=6`, answer is [d].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem 4 - training & testing\n",
    "# K is size of training set\n",
    "def problem_4(K): \n",
    "    X,Y = read_training_set()\n",
    "    Xtst,Ytst = read_test_set()\n",
    "    Xv,Yv,Xt,Yt = split_set(X,Y,K) # reversed sets\n",
    "    Xtx = transform_input_set(Xt)\n",
    "    Xtstx = transform_input_set(Xtst)\n",
    "    w = {}\n",
    "    Eout = {}\n",
    "    for k in range(3,8):\n",
    "        w[k] = solve_regression_k(Xtx, Yt, k)\n",
    "        Eout[k] = classification_error_k(w[k], Xtstx, Ytst, k)\n",
    "    for k in range(3,8):\n",
    "         print(f\"k = {k} , Eout = {Eout[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 , Eout = 0.396\n",
      "k = 4 , Eout = 0.388\n",
      "k = 5 , Eout = 0.284\n",
      "k = 6 , Eout = 0.192\n",
      "k = 7 , Eout = 0.196\n"
     ]
    }
   ],
   "source": [
    "problem_4(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smallest `Eout` for `k=6`, answer is [d].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "In problems 1 & 2, smallest `Eout=0.072` for `k=7`.\n",
    "\n",
    "In problems 3 & 4, smallest `Eout=0.192` for `k=6`.\n",
    "\n",
    "`(0.072, 0.192)` is closest to `(0.1, 0.2)`, answer is [b].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The PDF (probability distribution function) of $e_1$ and $e_2$ is $f(x) = 1$.  \n",
    "The expected value of $e_1$ and $e_2$ is:\n",
    "\n",
    "$$\\mathbb E(e_1) = \\mathbb E(e_2) = \\mathbb E(x) = \\int_{0}^1 x f(x) dx = \\frac{x^2}{2}\\Big|_0^1 = \\frac{1}{2} = 0.5$$\n",
    " \n",
    "The CDF (cumulative distribution function) of $e$ is:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "G(e) & = P(\\min(e_1,e_2) \\le e) \\\\\n",
    "& = 1 - P(\\min(e_1,e_2) > e) \\\\\n",
    "& = 1 - P(e_1 > e)P(e_2 > e) \\\\\n",
    "& = 1 - \\int_e^1 f(x) dx  \\int_e^1 f(x) dx \\\\\n",
    "& = 1 - (1-e)(1-e) \\\\\n",
    "& = 1 - (1-e)^2\n",
    "\\end{aligned}$$\n",
    "\n",
    "The PDF of $e$ is:\n",
    "\n",
    "$$g(e) = \\frac{dG(e)}{de} = 2(1-e)$$\n",
    "\n",
    "The expected value of $e$ is:\n",
    "\n",
    "$$\\mathbb E(e) = \\int_0^1 e(2(1-e)) de = e^2 - \\frac{2e^3}{3} \\Big|_0^1 = 1 - \\frac{2}{3} = \\frac{1}{3} = 0.333$$\n",
    "\n",
    "$$\\{E(e_1), E(e_2) , E(e)\\} = \\{0.5, 0.5, 0.33\\}$$\n",
    "\n",
    "The answer is closest to (0.5, 0.5, 0.4) i.e. [d].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p7a.png)\n",
    "![](hw7_images/hw7p7b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Let $P_1=(-1,0)$, $P_2=(1,0)$, $P_3=(\\rho,1)$.\n",
    "\n",
    "$P_1$ and $P_2$ sit on $x$-axis, $P_3$ is to the right of $y$-axis at height 1.\n",
    "\n",
    "Leave-one-out validation => fit model to two of the points, then test the fit on the third.\n",
    "\n",
    "For the constant model, $h_0(x) = b$. When we fit this model on two data points, $b$ will simply be the average of the $y$-coordinates of the two points.\n",
    "\n",
    "Leaving $P_1$ out, $b=\\frac{1}{2}$.\n",
    "- Error is $(h_0(x_1)-y_1)^2 = (b-0)^2 = \\left(\\frac{1}{2}\\right)^2$.\n",
    "\n",
    "Leaving $P_2$ out, $b=\\frac{1}{2}$.\n",
    "- Error is $(h_0(x_2)-y_2)^2 = (b-0)^2 = \\left(\\frac{1}{2}\\right)^2$.\n",
    "\n",
    "Leaving $P_3$ out, $b=0$.\n",
    "- Error is $(h_0(x_3)-y_3)^2 = (0-1)^2 = 1$.\n",
    "\n",
    "Overall $E_{cv}(h_0)$ is the average of the 3 errors:\n",
    "\n",
    "$$E_{cv}(h_0) = \\frac{\\frac{1}{4}+\\frac{1}{4}+1}{3} = \\frac{1}{2}$$\n",
    "\n",
    "We want to find $ρ$ that makes $E_{cv}(h_1) = \\frac{1}{2}$.\n",
    "\n",
    "When $P_3$ is left out, the fitted line is $y=0$ and the error is $(0-1)^2 = 1$.  \n",
    "\n",
    "When $P_2$ is left out, $h_1(x)$ is a line through $P_1$ and $P_3$.\n",
    "- Slope of line is $\\frac{y_3-y_1}{x_3-x_1} = \\frac{1}{\\rho+1}$\n",
    "- Intercept is $y_1-\\text{slope}*x_1 = \\frac{1}{\\rho+1}$\n",
    "- Error is $(h_1(x_2)-y_2)^2 = \\left(\\frac{2}{\\rho+1}\\right)^2$\n",
    "\n",
    "When $P_1$ is left out, $h_1(x)$ is a line through $P_2$ and $P_3$.\n",
    "- Slope of line is $\\frac{y_3-y_2}{x_3-x_2} = \\frac{1}{\\rho-1}$\n",
    "- Intercept is $y_2-\\text{slope}*x_2 = \\frac{-1}{\\rho-1}$\n",
    "- Error is $(h_1(x_1)-y_1)^2 = \\left(\\frac{-1}{\\rho-1} - \\frac{1}{\\rho-1}\\right)^2 = \\left(\\frac{-2}{\\rho-1}\\right)^2$\n",
    "\n",
    "Overall $E_{cv}(h_1)$ is $\\frac{1}{3}$[sum of 3 errors]:\n",
    "\n",
    "$$E_{cv}(h_1) = \\frac{1}{3} \\left[ 1 + \\left( \\frac{2}{\\rho+1} \\right)^2 + \\left( \\frac{-2}{\\rho-1} \\right)^2\\right]$$\n",
    "\n",
    "Set the two $E_{cv}$'s to be equal:\n",
    "\n",
    "$$E_{cv}(h_0) = E_{cv}(h_1)$$\n",
    "\n",
    "$$\\frac{1}{2} = \\frac{1}{3}\\left[ 1 + \\left( \\frac{2}{\\rho+1} \\right)^2 + \\left( \\frac{-2}{\\rho-1} \\right)^2\\right]$$\n",
    "\n",
    "A quadratic equation with one unknown. Using WolframAlpha:\n",
    "\n",
    "`solve 1 + (2/(x+1))^2 + (-2/(x-1))^2 - 3/2 = 0 for x` \n",
    "\n",
    "=> `x = sqrt(9 + 4*sqrt(6))`\n",
    "\n",
    "Answer is [c].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p8a.png)\n",
    "![](hw7_images/hw7p8b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems 8-10 - PLA vs SVM\n",
    " \n",
    "# dimension of input space d\n",
    "# number of data points = N\n",
    "# X is shape (N, d+1)\n",
    "def make_data_set(N, d):\n",
    "   X = np.zeros([N,d+1])\n",
    "   X[:,0] = np.ones([N,])\n",
    "   for i in range(1,d+1):\n",
    "       Xi = np.random.uniform(-1,1,N)\n",
    "       X[:,i] = Xi\n",
    "   return (X)\n",
    "    \n",
    "# the target function\n",
    "# d = 2\n",
    "# returns a tuple\n",
    "def make_line(): \n",
    "    x_1,y_1 = np.random.uniform(-1,1,2)\n",
    "    x_2,y_2 = np.random.uniform(-1,1,2)\n",
    "    slope = (y_1 - y_2) / (x_1 - x_2)\n",
    "    b = y_2 - slope * x_2\n",
    "    return (slope, b)\n",
    "\n",
    "# classify data set\n",
    "def classify_X(line, X):\n",
    "    slope, b = line\n",
    "    y = np.sign(X[:,1]*slope + b - X[:,2])\n",
    "    return(y)\n",
    "    \n",
    "# check if all points on one side of the line\n",
    "def is_X_valid(y):\n",
    "    N = np.size(y)\n",
    "    num_true = np.count_nonzero(y == 1)\n",
    "    if (num_true == N or num_true == 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pla\n",
    "# init guess is all zeros\n",
    "def pla(X, y, maxits):  \n",
    "    i = 0\n",
    "    w = np.zeros(X.shape[1])\n",
    "    while (i < maxits):\n",
    "        y_c = np.sign(np.dot(X, w))\n",
    "        if np.count_nonzero(y_c != y) == 0:\n",
    "            break\n",
    "        else:  # update perceptron with a misclassified point\n",
    "            misclassified_indices = (y_c != y).nonzero()[0]\n",
    "            ix = np.random.choice(misclassified_indices)\n",
    "            w = w + X[ix,:]*y[ix]\n",
    "        i += 1\n",
    "    return (w, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimated_error(w, X, y):\n",
    "    y_c = np.sign(np.dot(X, w)) \n",
    "    error = np.count_nonzero(y_c != y) / len(y)\n",
    "    return (error)\n",
    "\n",
    "def run_pla(N, d, max_iters):\n",
    "    while (1):\n",
    "        X = make_data_set(N, d)\n",
    "        sb = make_line()\n",
    "        y = classify_X(sb, X)\n",
    "        if is_X_valid(y):\n",
    "            break\n",
    "    (w, iters) = pla(X, y, max_iters)\n",
    "    return (X, y, sb, w, iters)\n",
    "\n",
    "# estimate Eout for the PLA run\n",
    "def eval_pla(N_test, d, sb, w):\n",
    "    X_test = make_data_set(N_test, d)\n",
    "    y_test = classify_X(sb, X_test)\n",
    "    error_test = estimated_error(w, X_test, y_test)\n",
    "    return (error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# use cvxopt package\n",
    "# status either 'optimal' or 'unknown'\n",
    "def svm(X, y):\n",
    "    # minimize (1/2)*x.T*P*x + q.T*x\n",
    "    # subject to G*x ≤ h and A*x = b\n",
    "    N = np.size(y)\n",
    "    X_trunc = X[:,1:]\n",
    "    x1_x2 = X_trunc @ X_trunc.T\n",
    "    y1_y2 = np.outer(y, y)\n",
    "    eye_neg = -np.eye(N)\n",
    "    # these are cvxopt matrices\n",
    "    P = cvxopt.matrix(x1_x2*y1_y2)\n",
    "    q = cvxopt.matrix(-1.0, (N,1))\n",
    "    G = cvxopt.matrix(eye_neg)\n",
    "    h = cvxopt.matrix(0.0, (N,1))\n",
    "    A = cvxopt.matrix(y, (1,N))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "    sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    # convert cvxopt solution matrix to numpy array\n",
    "    alpha = np.array(sol['x']).T[0]\n",
    "    # calculate w_trunc, b, and w\n",
    "    w_trunc = svm_calc_w_trunc(alpha, y, X)\n",
    "    b = svm_calc_b(alpha, y, X, w_trunc)\n",
    "    w = np.insert(w_trunc, 0, b)\n",
    "    return (sol['status'], alpha, w)\n",
    "\n",
    "# w_trunc is length d\n",
    "def svm_calc_w_trunc(alpha, y, X):\n",
    "    X_trunc = X[:,1:]\n",
    "    w_trunc = alpha*y@X_trunc\n",
    "    return (w_trunc)\n",
    "\n",
    "# b (i.e. w0) is a scalar\n",
    "def svm_calc_b(alpha, y, X, w_trunc):\n",
    "    X_trunc = X[:,1:]\n",
    "    # index of largest alpha\n",
    "    i = np.argmax(alpha)\n",
    "    b = 1/y[i] - np.dot(w_trunc, X_trunc[i,:])\n",
    "    return (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate Eout for the SVM run\n",
    "def eval_svm(N_test, d, sb, w):\n",
    "    X_test = make_data_set(N_test, d)\n",
    "    y_test = classify_X(sb, X_test)\n",
    "    error_test = estimated_error(w, X_test, y_test)\n",
    "    return (error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems 8, 9, and 10\n",
    "# N = 10 and N = 100, num_runs = 1000\n",
    "def problems_8_to_10(N, num_runs):\n",
    "    time_start = time.time()\n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    d = 2\n",
    "    max_iters = int(1e6)\n",
    "    N_test = int(1e6)\n",
    "    i = 0\n",
    "    Eout_pla = np.zeros(num_runs)\n",
    "    Eout_svm = np.zeros(num_runs)\n",
    "    num_sv = np.zeros(num_runs)\n",
    "    tol_sv = 1e-6 # this may be too tight\n",
    "    while True:\n",
    "        try: \n",
    "            X,y,sb,w,iters = run_pla(N,d,max_iters)\n",
    "            Eout_pla_i = eval_pla(N_test,d,sb,w)\n",
    "            status,alpha,w_svm = svm(X,y)\n",
    "            if status != 'optimal':\n",
    "                # svm did not converge. repeat pla & svm with new data set\n",
    "                raise RuntimeError('Optimization did not converge.')\n",
    "        except:\n",
    "            print(f'\\nSVM in run={i} did not converge. Repeat with new data set.',\\\n",
    "                  flush = True)\n",
    "            continue\n",
    "        # svm converged\n",
    "        Eout_svm_i = eval_svm(N_test,d,sb,w_svm)\n",
    "        Eout_pla[i] = Eout_pla_i\n",
    "        Eout_svm[i] = Eout_svm_i\n",
    "        num_sv[i] = np.count_nonzero((alpha > tol_sv) == True)\n",
    "        i +=1\n",
    "        perc_complete = 100*i/num_runs\n",
    "        # this line does not work without the \\r in the beginning\n",
    "        print(f'\\rJob {perc_complete:3.1f}% complete.', end = '\\r', flush = True)\n",
    "        if i == num_runs:\n",
    "            print()\n",
    "            break\n",
    "    compare_Eout = Eout_svm <= Eout_pla\n",
    "    perc_svm_better = 100*np.count_nonzero(compare_Eout == True)/num_runs\n",
    "    print(f\"Percentage of time SVM better than PLA = {perc_svm_better}%\")\n",
    "    num_sv_avg = np.mean(num_sv)\n",
    "    print(f\"Average number of support vectors = {num_sv_avg}\")\n",
    "    time_end = time.time()\n",
    "    print(f\"Run time = {(time_end - time_start):3.1f} seconds.\")\n",
    "    return (perc_svm_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 100.0% complete.\n",
      "Percentage of time SVM better than PLA = 61.9%\n",
      "Average number of support vectors = 3.01\n",
      "Run time = 296.2 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems_8_to_10(10,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer is closest to 60%, [c].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 100.0% complete.\n",
      "Percentage of time SVM better than PLA = 65.0%\n",
      "Average number of support vectors = 3.511\n",
      "Run time = 349.3 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems_8_to_10(100,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer is closest to 70%, [d].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hw7_images/hw7p10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "For `N=100`, average number of support vectors is `3.647`.\n",
    "\n",
    "Answer is closest to 3 i.e. [b]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
